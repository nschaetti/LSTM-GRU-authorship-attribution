#!/bin/bash

# WV pre-trained
# python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 300 --feature wv --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 WV-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Word Vectors (WV) pretrained with Glove" --rnn-type LSTM --epoch 250 --batch-size 64 --pretrained --verbose 4

# WV trained 50
# python2.7 model_rnn_keras_sentence.py --hidden-size 100 --cell-size 100 --embedding-size 50 --feature wv --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 100-100 WV-50 keras" --description "Authorship Attribution Sentence 15 authors LSTM 100 hidden neurons, Word Vectors (WV) trained size 50" --rnn-type LSTM --epoch 100 --batch-size 64 --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 50 --feature wv --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 WV-50 keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Word Vectors (WV) trained size 50" --rnn-type LSTM --epoch 100 --batch-size 64 --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 300 --cell-size 300 --embedding-size 50 --feature wv --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 300-300 WV-50 keras" --description "Authorship Attribution Sentence 15 authors LSTM 300 hidden neurons, Word Vectors (WV) trained size 50" --rnn-type LSTM --epoch 100 --batch-size 32 --verbose 4 --cuda

# POS trained
# python2.7 model_rnn_keras_sentence.py --hidden-size 100 --cell-size 100 --embedding-size 50 --feature pos --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 100-100 POS-10 keras" --description "Authorship Attribution Sentence 15 authors LSTM 100 hidden neurons, Part-of-Speech (POS) trained size 10" --rnn-type LSTM --epoch 150 --batch-size 64 --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 50 --feature pos --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 POS-10 keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Part-of-Speech (POS) trained size 10" --rnn-type LSTM --epoch 150 --batch-size 64 --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 300 --cell-size 300 --embedding-size 50 --feature pos --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 300-300 POS-10 keras" --description "Authorship Attribution Sentence 15 authors LSTM 300 hidden neurons, Part-of-Speech (POS) trained size 10" --rnn-type LSTM --epoch 150 --batch-size 64 --verbose 4 --cuda

# FW pretrained
# python2.7 model_rnn_keras_sentence.py --hidden-size 100 --cell-size 100 --embedding-size 300 --feature fw --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 100-100 FW-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 100 hidden neurons, Function Words (FW) pretrained with Glove" --rnn-type LSTM --epoch 200 --batch-size 64 --pretrained --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 300 --feature fw --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 FW-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Function Words (FW) pretrained with Glove" --rnn-type LSTM --epoch 200 --batch-size 64 --pretrained --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 300 --cell-size 300 --embedding-size 300 --feature fw --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 300-300 FW-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 300 hidden neurons, Function Words (FW) pretrained with Glove" --rnn-type LSTM --epoch 200 --batch-size 64 --pretrained --verbose 4 --cuda

# FW trained
# python2.7 model_rnn_keras_sentence.py --hidden-size 100 --cell-size 100 --embedding-size 20 --feature fw --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 100-100 FW-20 keras" --description "Authorship Attribution Sentence 15 authors LSTM 100 hidden neurons, Function Words (FW)" --rnn-type LSTM --epoch 200 --batch-size 64 --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 20 --feature fw --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 FW-20 keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Function Words (FW)" --rnn-type LSTM --epoch 200 --batch-size 64 --verbose 4 --cuda
# python2.7 model_rnn_keras_sentence.py --hidden-size 300 --cell-size 300 --embedding-size 20 --feature fw --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 300-300 FW-20 keras" --description "Authorship Attribution Sentence 15 authors LSTM 300 hidden neurons, Function Words (FW)" --rnn-type LSTM --epoch 200 --batch-size 64 --verbose 4 --cuda

# C1 pre-trained
# python2.7 model_rnn_keras_sentence.py --hidden-size 100 --cell-size 100 --embedding-size 10 --feature c1 --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 100-100 C1-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 100 hidden neurons, Character (C1) pretrained" --rnn-type LSTM --epoch 250 --batch-size 32 --pretrained --verbose 4 --cuda --embedding-path ~/Projets/TURING/Recherches/MLE/PhD/Reuters-C50-Authorship-Attribution/embeddings/char_embedding/c1_cx2_d10.p
python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 10 --feature c1 --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 C1-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Character (C1) pretrained" --rnn-type LSTM --epoch 250 --batch-size 32 --pretrained --verbose 4 --cuda --embedding-path ~/Projets/TURING/Recherches/MLE/PhD/Reuters-C50-Authorship-Attribution/embeddings/char_embedding/c1_cx2_d10.p
python2.7 model_rnn_keras_sentence.py --hidden-size 300 --cell-size 300 --embedding-size 10 --feature c1 --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 300-300 C1-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 300 hidden neurons, Character (C1) pretrained" --rnn-type LSTM --epoch 250 --batch-size 16 --pretrained --verbose 4 --cuda --embedding-path ~/Projets/TURING/Recherches/MLE/PhD/Reuters-C50-Authorship-Attribution/embeddings/char_embedding/c1_cx2_d10.p

# C2 pre-trained
python2.7 model_rnn_keras_sentence.py --hidden-size 100 --cell-size 100 --embedding-size 30 --feature c1 --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 100-100 C2-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 100 hidden neurons, Character (C2) pretrained" --rnn-type LSTM --epoch 250 --batch-size 64 --pretrained --verbose 4 --cuda --embedding-path ~/Projets/TURING/Recherches/MLE/PhD/Reuters-C50-Authorship-Attribution/embeddings/char_embedding/c2_cx2_d30.p
python2.7 model_rnn_keras_sentence.py --hidden-size 200 --cell-size 200 --embedding-size 30 --feature c1 --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 200-200 C2-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 200 hidden neurons, Character (C2) pretrained" --rnn-type LSTM --epoch 250 --batch-size 32 --pretrained --verbose 4 --cuda --embedding-path ~/Projets/TURING/Recherches/MLE/PhD/Reuters-C50-Authorship-Attribution/embeddings/char_embedding/c2_cx2_d30.p
python2.7 model_rnn_keras_sentence.py --hidden-size 300 --cell-size 300 --embedding-size 30 --feature c1 --learning-window 40 --max-length 40 --k 10 --output outputs/ --name "AAS Na15 LSTM 300-300 C2-P keras" --description "Authorship Attribution Sentence 15 authors LSTM 300 hidden neurons, Character (C2) pretrained" --rnn-type LSTM --epoch 250 --batch-size 16 --pretrained --verbose 4 --cuda --embedding-path ~/Projets/TURING/Recherches/MLE/PhD/Reuters-C50-Authorship-Attribution/embeddings/char_embedding/c2_cx2_d30.p
